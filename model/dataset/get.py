"""
Dataset Download and Organization Script

Downloads the fish disease dataset from Roboflow and organizes it
into the structure expected by the training script.

Usage:
    ROBOFLOW_API_KEY=your_key python dataset/get.py
"""

import os
import shutil
from pathlib import Path

from roboflow import Roboflow


# Disease classes in the dataset (from Roboflow)
DISEASE_CLASSES = [
    "bacterial_infection",
    "fungal_infection",
    "healthy",
    "parasite",
    "white_tail",
]


def download_dataset(
    api_key: str,
    workspace: str,
    project_name: str,
    version_number: int,
    format: str = "yolov8",
):
    """Download dataset from Roboflow."""
    rf = Roboflow(api_key=api_key)
    project = rf.workspace(workspace).project(project_name)
    version = project.version(version_number)
    dataset = version.download(format)
    return dataset


def organize_dataset(source_dir: Path, target_dir: Path, test_dir: Path) -> None:
    """
    Organize downloaded dataset into the expected structure.

    Source structure (Roboflow):
        source_dir/
            train/images/
            train/labels/
            valid/images/
            valid/labels/
            test/images/
            test/labels/
            data.yaml

    Target structure (our training expects):
        target_dir/
            images/train/
            images/val/
            labels/train/
            labels/val/
            data.yaml

        test_dir/ (separate, for final evaluation only)
            images/
            labels/
    """
    target_dir.mkdir(parents=True, exist_ok=True)

    # Create target directories
    (target_dir / "images" / "train").mkdir(parents=True, exist_ok=True)
    (target_dir / "images" / "val").mkdir(parents=True, exist_ok=True)
    (target_dir / "labels" / "train").mkdir(parents=True, exist_ok=True)
    (target_dir / "labels" / "val").mkdir(parents=True, exist_ok=True)

    # Copy training images and labels
    src_train_images = source_dir / "train" / "images"
    src_train_labels = source_dir / "train" / "labels"

    if src_train_images.exists():
        for img in src_train_images.glob("*"):
            shutil.copy2(img, target_dir / "images" / "train" / img.name)

    if src_train_labels.exists():
        for lbl in src_train_labels.glob("*"):
            shutil.copy2(lbl, target_dir / "labels" / "train" / lbl.name)

    # Copy validation images and labels (Roboflow uses "valid")
    src_valid_images = source_dir / "valid" / "images"
    src_valid_labels = source_dir / "valid" / "labels"

    if src_valid_images.exists():
        for img in src_valid_images.glob("*"):
            shutil.copy2(img, target_dir / "images" / "val" / img.name)

    if src_valid_labels.exists():
        for lbl in src_valid_labels.glob("*"):
            shutil.copy2(lbl, target_dir / "labels" / "val" / lbl.name)

    # Copy test images and labels to separate directory (for final evaluation)
    test_dir.mkdir(parents=True, exist_ok=True)
    (test_dir / "images").mkdir(parents=True, exist_ok=True)
    (test_dir / "labels").mkdir(parents=True, exist_ok=True)

    src_test_images = source_dir / "test" / "images"
    src_test_labels = source_dir / "test" / "labels"

    if src_test_images.exists():
        for img in src_test_images.glob("*"):
            shutil.copy2(img, test_dir / "images" / img.name)

    if src_test_labels.exists():
        for lbl in src_test_labels.glob("*"):
            shutil.copy2(lbl, test_dir / "labels" / lbl.name)

    # Create data.yaml with correct paths
    create_data_yaml(target_dir)

    # Print summary
    train_count = len(list((target_dir / "images" / "train").glob("*")))
    val_count = len(list((target_dir / "images" / "val").glob("*")))
    test_count = len(list((test_dir / "images").glob("*")))
    print(f"\nDataset organized successfully!")
    print(f"  Training images: {train_count}")
    print(f"  Validation images: {val_count}")
    print(f"  Test images: {test_count} (in {test_dir})")
    print(f"  Classes: {DISEASE_CLASSES}")


def create_data_yaml(target_dir: Path) -> None:
    """Create the data.yaml configuration file."""
    yaml_content = f"""# Fish Disease Detection Dataset
# Auto-generated by dataset/get.py

path: {target_dir.absolute()}
train: images/train
val: images/val

# Class names
names:
  0: bacterial_infection
  1: fungal_infection
  2: healthy
  3: parasite
  4: white_tail

# Number of classes
nc: 5
"""

    yaml_path = target_dir / "data.yaml"
    yaml_path.write_text(yaml_content)
    print(f"Created data.yaml at: {yaml_path}")


def main():
    API_KEY = os.getenv("ROBOFLOW_API_KEY")
    if not API_KEY:
        raise RuntimeError("ROBOFLOW_API_KEY is not set in the environment")

    WORKSPACE = "mina-orfdd"
    PROJECT = "mina-u7bag"
    VERSION = 2

    print("Downloading dataset from Roboflow...")
    dataset = download_dataset(
        api_key=API_KEY,
        workspace=WORKSPACE,
        project_name=PROJECT,
        version_number=VERSION,
    )

    # Get the downloaded directory path
    # Roboflow downloads to current directory with format: {project}-{version}
    source_dir = Path(dataset.location)
    print(f"Downloaded to: {source_dir}")

    # Organize into our expected structure
    model_dir = Path(__file__).parent.parent
    target_dir = model_dir / "data"
    test_dir = model_dir / "test_data"

    print(f"\nOrganizing dataset to: {target_dir}")
    print(f"Test data will be saved to: {test_dir}")
    organize_dataset(source_dir, target_dir, test_dir)

    # clean up the original download
    shutil.rmtree(source_dir)


if __name__ == "__main__":
    main()
